# Session 31 — 2026-02-22

## Context
- **Phase**: Phase 2.5: BarrierNet Experiment — Session 6 (CUDA Optimization + Training Acceleration)
- **Branch**: main

## Objectives
- [x] Diagnose slow training (40h estimate on CPU-only)
- [x] Add CUDA device support to BarrierNet training pipeline
- [x] Benchmark GPU vs CPU QP solving
- [x] Implement hybrid CPU/GPU training (CPU rollout + GPU PPO update)
- [x] Restart training on niro-2 with optimized pipeline
- [ ] Training in progress (~4.5h estimated)
- [ ] Auto-evaluation runs when training completes

## Work Done

### Performance Diagnosis
- Training at 47K/2M steps after 57 minutes (CPU-only)
- Actual rate: 13.7 steps/sec (~73ms/step)
- Initial 10.6h estimate was wrong — true estimate was ~40 hours
- Root cause: PPO update runs QP with gradients for every mini-batch
  - 10 epochs × 4 batches/epoch × ~1.7s per batch QP solve = ~69s per update
  - Rollout (no_grad): ~5.1s per iteration

### GPU QP Benchmarking
- qpth works on CUDA (RTX 5090) — tested with simple QP
- **CPU batch QP (B=256): 825ms**
- **GPU batch QP (B=256): 24ms**
- **34.6x speedup with GPU!**

### CUDA Support Added
- `scripts/train_barriernet.py`: Added `--device` flag (auto/cpu/cuda)
- `agents/barriernet_ppo.py`: Fixed device mismatch in `update()` (last_obs)
- `training/barriernet_trainer.py`: Device-aware tensor operations in rollout

### Hybrid CPU/GPU Training
- Problem: GPU inference for batch=1 rollout is slower than CPU (15ms vs 5ms)
  due to CPU↔GPU transfer overhead per step
- Solution: CPU copy of agent for rollout inference, GPU for batched PPO update
- Weight sync: `_sync_cpu_agent()` copies GPU weights to CPU after each update
- Result: **8.3s per iteration** (was 74s CPU-only, 18.5s GPU-only)
  - CPU rollout: ~5.5s (1024 × 5.4ms)
  - GPU PPO update: ~2.8s (vs 69s on CPU)
  - Weight sync: negligible

### Training Progress
- Restarted with hybrid training (PID 2257137)
- ETA: ~4.5 hours for 2M steps
- 0% infeasibility throughout
- Monitor script (PID 2321446) watching for completion

## Files Changed
| File | Action | Description |
|------|--------|-------------|
| `scripts/train_barriernet.py` | Modified | Added --device arg, agent.to(device) |
| `agents/barriernet_ppo.py` | Modified | Fixed device mismatch: last_obs.to(device) |
| `training/barriernet_trainer.py` | Modified | Hybrid CPU/GPU: CPU rollout + GPU update |
| `docs/worklogs/2026-02-22_S31.md` | Created | Session worklog |

## Decisions Made
| Decision | Rationale |
|----------|-----------|
| Hybrid CPU/GPU over full GPU | CPU is faster for batch=1 rollout (5ms vs 15ms) |
| deepcopy for CPU agent | Clean separation, no shared state between devices |
| Weight sync after every update | Ensures CPU agent uses latest policy for exploration |
| Kill/restart training | New approach 9x faster; 47K steps of lost progress negligible |

## Issues & Blockers
| Issue | Resolution |
|-------|------------|
| Training estimated 40h on CPU-only | GPU QP 34.6x faster → hybrid approach reduces to ~4.5h |
| Device mismatch in update() | Added .to(self.device) for buffer tensors |
| GPU batch=1 slower than CPU | Hybrid: CPU for rollout, GPU for batched update |
| Training PID shell expansion | Used heredoc with quoted delimiter |

## Next Steps
- [ ] Training completes (~4.5h from launch)
- [ ] Auto-evaluation runs (200 episodes)
- [ ] Review comparison results (BarrierNet vs baseline PPO)
- [ ] Decision analysis document

## Metrics
- Files modified: 3
- Training speedup: 9x (40h → 4.5h)
- GPU QP speedup: 34.6x (825ms → 24ms for B=256)
- Commits: 79a929e, a502c99, 3b9bd0a
