# Session 57 — 2026-02-27

## Context
- **Phase**: Phase 3 — Partial Observability & Self-Play
- **Branch**: main

## Objectives
- [x] Implement adaptive training ratio for self-play anti-cycling
- [x] Implement LR dampening near equilibrium
- [x] Add CLI args and tests
- [ ] Launch RA7/RA8 on niro-2

## Work Done

### Adaptive Training Ratio + LR Dampening
RA5/RA6 analysis showed reward fix (±50 terminal, 10x10, 1.05x, no PBRS) eliminated permanent one-sided collapse but introduced classic self-play cycling. RA6 hit gap=0.06 at M150 (streak 2/5) then pursuer surged to SR_P=1.00 by M350 and dominated for 2M steps.

Root causes:
1. Equal training budget when one agent dominates (winner wastes steps, loser can't catch up)
2. Constant LR causes overshooting near equilibrium

Implemented two anti-cycling mechanisms:
- **Adaptive training ratio**: When NE gap exceeds threshold, gives the losing agent extra consecutive training phases (default: 20 boost phases). This lets the loser catch up faster.
- **LR dampening**: When NE gap is below threshold (near equilibrium), scales LR down proportionally (`lr * max(0.1, gap/threshold)`). Prevents overshooting that triggers cycling.

Both mechanisms are disabled by default (threshold=0.0) for backward compatibility.

### Tests
Added 3 new tests:
- `test_amsdrl_adaptive_ratio_defaults` — verifies disabled by default
- `test_amsdrl_lr_dampen_defaults` — verifies disabled by default
- `test_amsdrl_accepts_adaptive_params` — verifies custom values stored correctly

All 30 opponent pool tests pass. No regressions in full test suite.

## Files Changed
| File | Action | Description |
|------|--------|-------------|
| `training/amsdrl.py` | Modified | Added 3 new __init__ params, adaptive ratio + LR dampening logic in _run_micro_phases |
| `scripts/train_amsdrl.py` | Modified | Added 3 CLI args, pass-through to AMSDRLSelfPlay |
| `tests/test_opponent_pool.py` | Modified | Added 3 new tests for adaptive params |
| `docs/worklogs/2026-02-27_S57.md` | Created | This worklog |
| `docs/workflow_tracker.md` | Modified | Added S57 entry |

## Decisions Made
| Decision | Rationale |
|----------|-----------|
| Boost phases = 20 default | ~1M extra steps for loser at 2048 steps/phase, enough to recover from moderate imbalance |
| LR scale floor = 0.1 | Prevents LR from going to zero; 10x reduction is aggressive enough |
| Both disabled by default | Backward compatible with existing configs; opt-in for RA7/RA8 |
| Boost triggers on gap > threshold | Only intervene when imbalance is significant, not during normal alternation |

## Issues & Blockers
| Issue | Resolution |
|-------|------------|
| None | — |

## Next Steps
- [ ] Kill RA5/RA6 on niro-2
- [ ] Push code and launch RA7 (adaptive_ratio=0.3 + lr_dampen=0.3) and RA8 (adaptive_ratio=0.3 only)
- [ ] Monitor boost activations and gap stability

## Metrics
- Files changed: 3
- Tests added: 3
- Documents updated: 2
