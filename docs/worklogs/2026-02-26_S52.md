# Session 52 — 2026-02-26

## Context
- **Phase**: Phase 3: Partial Observability & Self-Play
- **Branch**: main
- **Prereq**: S51 identified 8 root causes for evader L2 collapse, recommended 9 fixes in 3 tiers

## Objectives
- [x] Implement Tier 1 fixes: bilateral rollback, evader-first at new levels
- [x] Implement Tier 2 fixes: warm-start evader, mixed-level replay, smooth curriculum
- [x] Launch training Runs V+W (Tier 1+2) and X+Y (Tier 1+2+3) — 4 runs total
- [x] Implement Tier 3: EWC (Fix 5) and RND (Fix 9) — catastrophic forgetting prevention and exploration
- [x] Add tests for all new features (40 tests)
- [x] Update documentation

## Work Done

### Tier 1+2 Fixes (from first part of session)
- **Bilateral rollback**: `--bilateral_rollback` flag in AMSDRLSelfPlay
- **Evader-first on advance**: `--evader_first_on_advance` forces evader training at new curriculum levels
- **Warm-start evader**: `--warm_start_evader` with `--warm_start_timesteps` restores and pre-trains evader at transitions
- **Mixed-level replay**: `--mixed_level_ratio 0.2` keeps 20% of envs at previous level distances
- **Smooth curriculum**: `--smooth_curriculum` with `--smooth_curriculum_increment 0.5` for continuous difficulty scaling
- All Tier 1+2 CLI args added to `scripts/train_amsdrl.py`

### Training Runs V, W, X, Y Launched
- **Run V**: Equal speed (pursuer=1.0, evader=1.0), Tier 1+2 only, seed=47
- **Run W**: Pursuer 95% speed (pursuer=0.95, evader=1.0), Tier 1+2 only, seed=47
- **Run X**: Equal speed + Tier 3 (EWC λ=1000, RND coef=0.1), seed=47
- **Run Y**: Pursuer 95% + Tier 3 (EWC λ=1000, RND coef=0.1), seed=47
- All 4 running in background on local machine

### Tier 3: EWC (Elastic Weight Consolidation) — `training/ewc.py`
- `EWCRegularizer` class with:
  - `snapshot(model, obs_batch)`: saves theta_star, computes diagonal Fisher info via policy log-prob gradients
  - `register_hooks(model)`: injects `lambda * F * (theta - theta_star)` into gradients via PyTorch hooks
  - `remove_hooks(handles)`: cleans up after training
  - `penalty(model)`: scalar penalty for logging
- Integrates with SB3 PPO without subclassing — hooks inject EWC gradient during standard backprop
- Triggered on curriculum advancement in `AMSDRLSelfPlay.run()` via `_ewc_snapshot_evader()`

### Tier 3: RND (Random Network Distillation) — `envs/rnd.py`
- `RunningMeanStd`: Welford's online algorithm for reward normalization
- `RNDModule(nn.Module)`: frozen target + trainable predictor MLPs `[obs_dim] → [hidden] → [hidden] → [embed]`
- `RNDRewardWrapper(gym.Wrapper)`: wraps evader env, augments reward with `rnd_coef * normalized_intrinsic`
  - Handles both flat Box and Dict observation spaces via `_flatten_obs()`
  - Periodic predictor training every `update_freq` steps
  - Logs `rnd_intrinsic`, `rnd_extrinsic`, `rnd_total` in info dict
- Threaded through `_make_vec_env()` and `_train_phase()` — lazy module creation on first evader phase

### AMSDRL Integration
- Added `ewc_lambda`, `ewc_fisher_samples`, `rnd_coef`, `rnd_embed_dim`, `rnd_hidden_dim`, `rnd_update_freq` params
- EWC: snapshot on curriculum advancement, hooks around evader's `model.learn()`
- RND: wraps evader envs via `_make_vec_env()`, lazy init to auto-detect obs_dim
- Both disabled by default (lambda=0, coef=0) — zero runtime overhead when not used

### Tests (40 new tests)
- `tests/test_ewc.py`: 17 tests — init, snapshot, Fisher, penalty, hooks, training integration
- `tests/test_rnd.py`: 23 tests — RunningMeanStd, RNDModule, RNDRewardWrapper, Monitor compatibility

## Files Changed
| File | Action | Description |
|------|--------|-------------|
| `training/ewc.py` | Created | EWC regularizer with snapshot, hooks, penalty |
| `envs/rnd.py` | Created | RND module, reward wrapper, RunningMeanStd |
| `training/amsdrl.py` | Modified | EWC/RND integration: imports, __init__ params, _ewc_snapshot_evader(), _train_phase() hooks, _make_vec_env() RND wrapping |
| `scripts/train_amsdrl.py` | Modified | 6 new CLI args for EWC/RND |
| `tests/test_ewc.py` | Created | 17 EWC tests |
| `tests/test_rnd.py` | Created | 23 RND tests |

## Decisions Made
| Decision | Rationale |
|----------|-----------|
| EWC via gradient hooks (not PPO subclass) | Non-invasive integration with SB3; hooks inject penalty gradient during standard backprop |
| RND wraps after PartialObsWrapper | Flat concatenation of Dict obs ensures consistent input dim; operates on agent's actual observation |
| Lazy RND module creation | Auto-detects obs_dim on first evader training phase; handles Dict/Box spaces |
| Skip Fix 7 (diversity pool) | Already have `OpponentPool`; EWC+RND address the core forgetting/exploration issues |
| Dict obs flattening in RND | Sorts keys alphabetically for deterministic concatenation order |

## Issues & Blockers
| Issue | Resolution |
|-------|------------|
| Dict obs space from PartialObsWrapper | Added `_flatten_obs()` to RNDRewardWrapper; flattened dim calc in `_train_phase()` |
| Tests needed `MultiInputPolicy` for Dict space | Used full_obs (flat Box) for EWC/RND unit tests; integration handled in AMSDRL |
| Local training OOM'd (8 GB MacBook, 4 concurrent runs) | Moved all training to niro-2 (125 GB RAM). Updated CLAUDE.md: NEVER train locally |
| RTX 5090 (sm_120) incompatible with PyTorch 2.6 | Forced CPU via `CUDA_VISIBLE_DEVICES=""`. 24 cores handles 4 concurrent runs fine |
| Python stdout buffering hides nohup logs | Logs flush on print(); check checkpoints/TB dirs for real-time progress instead |

## Next Steps
- [ ] Monitor all 4 runs for L2 collapse — check `results/run_*/history.json` once generated
- [ ] Compare V vs X (and W vs Y) to isolate Tier 3 effect
- [ ] Compare V vs W (and X vs Y) to isolate speed advantage effect
- [ ] If all collapse: rethink curriculum increment or reward structure
- [ ] If Tier 3 helps: tune EWC lambda and RND coefficient via grid search
- [ ] Proceed to Phase 4 (sim-to-real) once self-play converges

## Active Training Runs (launched 2026-02-26 ~03:55 on niro-2)

All 4 runs share: smooth curriculum (0.5m increment), 10x10 arena, fixed speed, seed=47,
bilateral rollback, evader-first on advance, warm-start evader (50K steps), mixed-level
replay (20%), visibility reward (weight=1.0), survival bonus (0.05), PBRS obstacle-seeking
(w_obs_approach=50.0), prep steps (50).

| Run | Dir | Speed | Tier 3 | Key Question |
|-----|-----|-------|--------|-------------|
| V | `results/run_V_equal_speed` | 1.0/1.0 | No | Do structural fixes alone prevent L2 collapse? |
| W | `results/run_W_pursuer95` | 0.95/1.0 | No | Does speed advantage help? |
| X | `results/run_X_equal_speed_tier3` | 1.0/1.0 | EWC λ=1000, RND=0.1 | Does EWC+RND prevent forgetting at equal speed? |
| Y | `results/run_Y_pursuer95_tier3` | 0.95/1.0 | EWC λ=1000, RND=0.1 | Full stack — best chance of convergence |

**How to check progress (from local machine):**
```bash
# Check processes
sshpass -p '123456' ssh niro-2@100.71.2.97 "ps aux | grep train_amsdrl | grep python | grep -v grep | wc -l"

# Check logs (may be buffered; flush happens at phase boundaries)
sshpass -p '123456' ssh niro-2@100.71.2.97 "tail -30 ~/claude_pursuit_evasion/results/run_V_equal_speed/train.log"

# Check checkpoint progress (most reliable)
sshpass -p '123456' ssh niro-2@100.71.2.97 "for d in run_V_equal_speed run_W_pursuer95 run_X_equal_speed_tier3 run_Y_pursuer95_tier3; do echo === \$d ===; ls ~/claude_pursuit_evasion/results/\$d/checkpoints/pursuer/ 2>/dev/null | tail -3; echo; done"

# Check history.json (once phases complete)
sshpass -p '123456' ssh niro-2@100.71.2.97 "cat ~/claude_pursuit_evasion/results/run_V_equal_speed/history.json" | python -m json.tool

# Copy results locally
sshpass -p '123456' scp -r niro-2@100.71.2.97:~/claude_pursuit_evasion/results/run_V_equal_speed/history.json results/run_V_equal_speed/
```

**What to look for:**
- `escape_rate >= 0.05` sustained across levels = healthy
- `escape_rate → 0.0` after advancement = L2 collapse recurring
- Curriculum level advancing beyond 2 = success
- Each 500K-step phase takes ~40 min on CPU; expect L2 transitions around phases S3-S5 (~2-3h in)

## Metrics
- Files created: 4 (ewc.py, rnd.py, test_ewc.py, test_rnd.py)
- Files modified: 2 (amsdrl.py, train_amsdrl.py)
- Tests added: 40 (17 EWC + 23 RND)
- Total tests passing: 654 (614 core + 40 new, excluding 68 pre-existing Phase 2.5 BarrierNet failures)
