# Session 40 — 2026-02-22

## Context
- **Phase**: Phase 3: Partial Observability — Training & Observation Fix
- **Continuation**: From Session 39 (Sessions 1-2 implementation)

## Objectives
- [x] Fix NameError in pretrain_bimdn.py (val_loss undefined)
- [x] Fix CUDA OOM follow-up issues
- [x] Diagnose Gate 1 failure and fix root cause
- [x] Fix observation space: add own pose (x, y, theta)
- [x] Launch training on niro-2 (Stages 1 & 2)
- [ ] Wait for Stage 2 completion and evaluate results

## Work Done

### 1. NameError Fix
- `val_loss` was referenced but undefined after OOM refactoring
- Fixed to `val_losses[-1]` in pretrain_bimdn.py line 165

### 2. Gate 1 Failure Diagnosis — Critical Observation Space Bug
Ran Stage 1 training: BiMDN achieved In-FOV RMSE 8.76m and Out-FOV RMSE 9.65m — at or worse than random baseline (8.2m). The model learned nothing.

**Root cause**: The raw observation `[v, omega, d_to_opp, bearing, lidar_36]` (40 dims) does NOT include the agent's own position `(x, y, theta)`. Without knowing WHERE in the arena the agent is, converting relative sensor readings (d_to_opp, bearing) to absolute opponent position estimates is mathematically impossible.

The spec says "Own state (velocity, heading) is always known (odometry)" — heading should be included. And odometry always provides full (x, y, theta) in real robots.

### 3. Observation Space Fix
Added own pose (x, y, theta) to raw observation:
- **RAW_OBS_DIM**: 40 → 43
- **Raw obs layout**: `[x, y, theta, v, omega, d_to_opp, bearing, lidar_36]`
- **State features**: `[x, y, theta, v, omega, d_to_opp, bearing]` (4 → 7 dims)

Files changed: partial_obs_wrapper.py, partial_obs_policy.py, bimdn.py, encoders.py, phase3_pretrain_bimdn.py, test_bimdn.py

All 29 Phase 3 tests pass, full suite 436 passed (68 pre-existing failures in QP/BarrierNet).

### 4. Training Results Comparison (Stage 1)

| Metric | Run 1 (no pose, 64h, 50ep) | Run 2 (pose, 64h, 50ep) | Run 3 (pose, 128h, 100ep) | Target |
|--------|---------------------------|------------------------|---------------------------|--------|
| In-FOV RMSE | 8.76m (FAIL) | 0.81m (PASS) | **0.31m** (PASS) | < 2.0m |
| Out-FOV RMSE | 9.65m (FAIL) | 9.47m (FAIL) | 9.25m (FAIL) | < 5.0m |
| n_eff visible | 1.22 | 1.12 | **1.01** (PASS) | ~1.0 |
| n_eff lost | 1.23 | 1.10 (borderline) | **1.20** (PASS hard fail) | > 1.5 |
| Gate 1 | FAILED (2 hard) | FAILED (1 hard) | FAILED (1 hard) | |

In-FOV prediction improved from random-level to sub-meter. Out-of-FOV remains limited by data quality (88.7% of samples have zero target information with random data collection).

### 5. Stage 2 Training
Stage 2 (PPO + partial obs) launched successfully:
- Config 2A (BiMDN + DCBF): Running on niro-2
- Configs 2B and 2C: Will run sequentially after 2A
- Fixed tensorboard + tqdm/rich dependency issues

## Files Changed
| File | Action | Description |
|------|--------|-------------|
| `envs/partial_obs_wrapper.py` | Modified | Added own pose (x,y,theta) to obs; RAW_OBS_DIM 40→43, state 4→7 |
| `agents/partial_obs_policy.py` | Modified | Added state_dim parameter, updated defaults to 43/7 |
| `agents/bimdn.py` | Modified | Default obs_dim 40→43 |
| `agents/encoders.py` | Modified | Default obs_dim 40→43 for all encoders |
| `scripts/phase3_pretrain_bimdn.py` | Modified | Fixed val_loss NameError, updated obs_dim, visibility check index |
| `scripts/launch_stage1_and_2.sh` | Modified | Increased epochs 50→100, hidden_dim 64→128 |
| `tests/test_bimdn.py` | Modified | Updated all dims 40→43, state 4→7, d_to_opp index 2→5 |

## Decisions Made
| Decision | Rationale |
|----------|-----------|
| Add own pose (x,y,theta) to observation | Without own position, BiMDN cannot convert relative sensor readings to absolute position predictions. Spec says heading is known from odometry. In real robots, odometry always provides full pose. This is proprioception, not partial observability. |
| Increase hidden_dim to 128 | Training policy Gate 1 failure protocol recommends increasing LSTM hidden dim |
| Increase epochs to 100 | More training helps model learn temporal correlations |
| Proceed to Stage 2 despite Gate 1 partial failure | Out-of-FOV RMSE is fundamentally limited by random data collection. In-FOV metrics are excellent. Training policy says to continue after 2h of debugging. |

## Issues & Blockers
| Issue | Resolution |
|-------|------------|
| val_loss NameError | Changed to val_losses[-1] |
| Gate 1 Out-FOV RMSE ~9m | Root cause: no own-pose in observation. After fix: in-FOV 0.31m, out-FOV still 9.25m (limited by random data) |
| tensorboard not installed | pip install tensorboard |
| tqdm/rich not installed | pip install tqdm rich |

## Next Steps
- [ ] Wait for Stage 2 (3 configs x 500K steps) to complete on niro-2
- [ ] Analyze Stage 2 Gate 2 evaluation results
- [ ] If capture_rate is 0%, investigate reward shaping / environment dynamics
- [ ] Consider improving BiMDN out-of-FOV by using scripted policies for data collection (as spec recommends)
- [ ] Update workflow tracker

## Metrics
- Files changed: 7
- Tests: 29 pass (Phase 3), 436 pass (total suite)
- Training runs: 3 Stage 1 iterations, 1 Stage 2 running
