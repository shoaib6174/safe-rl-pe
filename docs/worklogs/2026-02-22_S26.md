# Session 26 — 2026-02-22

## Context
- **Phase**: Phase 2.5: BarrierNet Experiment — Session 1 (Differentiable QP Solver Research)
- **Branch**: main

## Objectives
- [x] Research cvxpylayers: API, GPU support, batching, performance, PyTorch 2.x compatibility
- [x] Research qpth: API, GPU support, performance, comparison with cvxpylayers
- [x] Research OptNet: current maintenance status
- [x] Research newer alternatives (2024-2025): dQP, SCQPTH, BPQP
- [x] Research BarrierNet (Xiao et al., T-RO 2023): architecture, infeasibility handling, overhead
- [x] Identify which diff QP library to use (cvxpylayers vs qpth)

## Work Done

### Differentiable QP Solver Landscape Research
- Conducted comprehensive web research across 15+ sources
- Compared 6 differentiable QP solvers: cvxpylayers, qpth, OptNet, dQP, SCQPTH, BPQP
- Analyzed BarrierNet and ABNet architectures for safe RL integration
- Compiled practical implementation details with API examples and performance benchmarks

### Key Findings
1. **cvxpylayers v1.0** (Jan 2026): Best general choice — PyTorch >= 2.0, GPU via CuClarabel, native batching, actively maintained
2. **qpth v0.0.18** (Sep 2024): Simpler API for dense QPs, native GPU PDIPM, but no sparsity support
3. **dQP** (NeurIPS 2025): Solver-agnostic (15+ solvers), best for sparse problems, but no GPU yet
4. **SCQPTH**: ADMM-based, 10-13x faster than qpth for large problems, but our problems are small
5. **BPQP** (NeurIPS 2024): Novel backward pass reformulation, order-of-magnitude faster
6. **BarrierNet**: Uses qpth + cvxpy, CBF-QP as differentiable last layer — same pattern as our Phase 3

### Recommendation for Our Project
For our specific problem (2 control variables, ~4 constraints), **qpth** is the pragmatic choice:
- Native GPU batched solving via PDIPM
- Simple API: `QPFunction()(Q, p, G, h, A, b)` — direct QP parameter input
- BarrierNet reference implementation uses it
- Our QPs are tiny (2 vars, ~4 constraints) — qpth overhead is negligible at this scale
- cvxpylayers adds CVXPY canonicalization overhead that's unnecessary when we already have QP form

## Files Changed
| File | Action | Description |
|------|--------|-------------|
| `docs/worklogs/2026-02-22_S26.md` | Modified | Completed worklog with research findings |

## Decisions Made
| Decision | Rationale |
|----------|-----------|
| qpth is best choice for Phase 3 differentiable safety layer | Small QP size (2 vars, ~4 constraints), native GPU batching, BarrierNet uses it, simpler API when QP form is known |
| cvxpylayers as fallback if we need sparsity or general conic programs later | More flexible but adds canonicalization overhead |
| BarrierNet architecture validates our Phase 2/3 design | Same CBF-QP-as-last-layer pattern we're implementing |

## Issues & Blockers
| Issue | Resolution |
|-------|------------|
| Could not access full BarrierNet T-RO PDF for detailed timing numbers | Used abstracts, related papers (ABNet), and code repository |

## Next Steps
- [ ] Clone BarrierNet repo and study the differentiable QP implementation code
- [ ] Prototype a minimal differentiable QP layer with qpth for our VCP-CBF
- [ ] Benchmark QP solve time for our specific problem size

## Metrics
- Sources consulted: 15+
- Solvers compared: 6
- Documents updated: 1
